---
phase: 06-planning-workflow
plan: 03
type: execute
wave: 2
depends_on: ["06-01", "06-02"]
files_modified:
  - scripts/test-plan-phase.js
  - package.json
autonomous: true

must_haves:
  truths:
    - "Integration test validates prompt builders produce correct output"
    - "Integration test validates pipeline orchestration logic with mock agents"
    - "Integration test validates config toggle gating (research on/off, checker on/off)"
    - "package.json has test:plan-phase script"
  artifacts:
    - path: "scripts/test-plan-phase.js"
      provides: "Integration test for plan-phase.js and discuss-phase.js modules"
      min_lines: 100
    - path: "package.json"
      provides: "test:plan-phase script entry"
      contains: "test:plan-phase"
  key_links:
    - from: "scripts/test-plan-phase.js"
      to: "src/plan-phase.js"
      via: "import"
      pattern: "import.*plan-phase"
    - from: "scripts/test-plan-phase.js"
      to: "src/discuss-phase.js"
      via: "import"
      pattern: "import.*discuss-phase"
---

<objective>
Create integration tests for the plan-phase and discuss-phase modules, and add the test script to package.json.

Purpose: Tests verify that prompt builders, expected file path computation, config gating logic, and discuss-phase helpers all work correctly. This catches path mismatches (the #1 pitfall from research), schema drift, and import errors before real agent execution. Following the established test pattern from Phase 5 (test-map-codebase.js).

Output: `scripts/test-plan-phase.js` integration test and updated `package.json`.
</objective>

<execution_context>
@/Users/memehalis/.claude/get-shit-done/workflows/execute-plan.md
@/Users/memehalis/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-planning-workflow/06-01-SUMMARY.md
@.planning/phases/06-planning-workflow/06-02-SUMMARY.md
@scripts/test-map-codebase.js
@src/plan-phase.js
@src/discuss-phase.js
@package.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create scripts/test-plan-phase.js integration test</name>
  <files>scripts/test-plan-phase.js</files>
  <action>
Create `scripts/test-plan-phase.js` following the EXACT test pattern from `scripts/test-map-codebase.js`:
- Shebang: `#!/usr/bin/env node`
- Module-level doc comment with description, run command, and npm script
- tmpdir isolation with cleanup in `finally` block
- `assert/strict` for assertions
- `test(name, fn)` helper with pass/fail tracking
- Summary at end with `process.exit(failed > 0 ? 1 : 0)`

Test categories:

**--- discuss-phase.js tests ---**

Test 1: `getContextTemplateSections returns 3 sections`
- Call `getContextTemplateSections()`
- Assert `success: true`
- Assert `data.sections` has exactly 3 entries: 'Decisions', "Claude's Discretion", 'Deferred Ideas'
- Assert `data.template` is a non-empty string containing all three section headers

Test 2: `getPhaseDetails reads phase from mock ROADMAP.md`
- Create a temp `.planning/` dir with a mock ROADMAP.md containing a Phase 6 section (use the real format from ROADMAP.md)
- Call `getPhaseDetails(tempPlanningDir, 6)`
- Assert success and that `data.name` contains "Planning Workflow"

Test 3: `getPhaseDetails returns error for missing phase`
- Call `getPhaseDetails(tempPlanningDir, 99)`
- Assert `success: false` and error contains "not found"

**--- plan-phase.js prompt builder tests ---**

Test 4: `buildResearchPrompt references agent definition`
- Call `buildResearchPrompt(6, 'Planning Workflow', 'details', 'context', '/tmp/phasedir')`
- Assert result has `prompt` and `outputFile`
- Assert prompt contains `agents/gsd-phase-researcher.md`
- Assert prompt contains phase number and name
- Assert outputFile ends with `06-RESEARCH.md`

Test 5: `buildPlannerPrompt references agent definition`
- Call `buildPlannerPrompt(6, 'Planning Workflow', 'details', 'context', 'research content', '/tmp/phasedir')`
- Assert prompt contains `agents/gsd-planner.md`
- Assert prompt contains `<user_decisions>` tags
- Assert prompt contains `<research>` tags
- Assert outputFile ends with `06-PLANS-DONE.md`

Test 6: `buildPlannerPrompt handles null context and research`
- Call with null contextContent and null researchContent
- Assert prompt does NOT contain `<user_decisions>` tags
- Assert prompt does NOT contain `<research>` tags
- Assert it still references the agent definition

Test 7: `buildCheckerPrompt references agent definition`
- Call `buildCheckerPrompt(6, 'Planning Workflow', 'context', '/tmp/phasedir')`
- Assert prompt contains `agents/gsd-plan-checker.md`
- Assert outputFile ends with `06-CHECK.md`

Test 8: `getExpectedPlanFiles returns correct paths`
- Call `getExpectedPlanFiles('/tmp/test/06-planning', '06')`
- Assert returned object has `research`, `plans`, `check` keys
- Assert each path starts with `/tmp/test/06-planning`
- Assert filenames match `06-RESEARCH.md`, `06-PLANS-DONE.md`, `06-CHECK.md`

**--- Config gating tests (mock pipeline) ---**

Do NOT test `runPlanningPipeline` (it spawns real processes). Instead, test the config-reading and gating logic:

Test 9: `Config with research=false skips research prompt building`
- Read default config, set `workflow.research = false`
- Verify that when `research` is false, the pipeline documentation says it should skip research
- This is a logic verification, not a process test -- just assert the config structure is parseable

Test 10: `Config defaults enable all pipeline stages`
- Call `readPlanningConfig` on a temp dir with no config.json (triggers defaults)
- Assert `data.workflow.research === true`
- Assert `data.workflow.plan_check === true`
- Assert `data.model_profile === 'quality'`

**Cleanup:** Remove temp dir in `finally` block.

Important: Do NOT test `runPlanningPipeline` directly -- it spawns real Cline processes. Only test the prompt builders, file path generators, and config parsing. This matches the pattern from Phase 5 where `runMapping` was explicitly excluded from testing.
  </action>
  <verify>
Run: `node scripts/test-plan-phase.js` -- should print all tests passing (10/10) and exit with code 0.
  </verify>
  <done>
Integration test passes 10/10 tests covering: discuss-phase template structure, phase detail extraction, prompt builder correctness, agent definition references, config gating logic, and file path conventions. Test follows established tmpdir isolation pattern from test-map-codebase.js.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add test:plan-phase script to package.json</name>
  <files>package.json</files>
  <action>
Read the current `package.json` and add a new script entry:
```json
"test:plan-phase": "node scripts/test-plan-phase.js"
```

Add it after the existing `test:map-codebase` entry to maintain alphabetical/chronological ordering. Do NOT modify any other fields.

After updating package.json, run the test to verify everything works end-to-end:
```bash
npm run test:plan-phase
```
  </action>
  <verify>
Run: `npm run test:plan-phase` -- should execute the test script and pass all tests.
Also verify: `node -e "import pkg from './package.json' with { type: 'json' }; console.log(pkg.default.scripts['test:plan-phase'] ? 'PASS' : 'FAIL');"` -- should print PASS.
  </verify>
  <done>
`package.json` has `test:plan-phase` script. `npm run test:plan-phase` executes successfully with all tests passing.
  </done>
</task>

</tasks>

<verification>
1. `node scripts/test-plan-phase.js` passes all 10 tests (exit code 0)
2. `npm run test:plan-phase` runs successfully
3. Tests cover: discuss-phase helpers, prompt builders, file path conventions, config gating
4. No test spawns real Cline processes
5. Tests use tmpdir isolation with cleanup in finally block
</verification>

<success_criteria>
- 10 integration tests passing in `scripts/test-plan-phase.js`
- Tests catch the key pitfalls: path mismatches, schema drift, config toggle behavior
- `package.json` has `test:plan-phase` script entry
- `npm run test:plan-phase` exits cleanly
</success_criteria>

<output>
After completion, create `.planning/phases/06-planning-workflow/06-03-SUMMARY.md`
</output>
